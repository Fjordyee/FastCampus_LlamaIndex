{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlamaIndex 기반 심플한 Naive-RAG 구성해보기\n",
    "\n",
    "- 활용 Dataset: Huggingface 코리안 웹텍스트 데이터셋 (https://huggingface.co/datasets/HAERAE-HUB/KOREAN-WEBTEXT) \n",
    "- * 인덱스 0~20까지.\n",
    "- 임베딩 모델: text-embedding-3-small\n",
    "- Generation 모델: gpt-4o-mini\n",
    "- 벡터DB : Qdrant\n",
    "- 노드(청크) 단위: 사이즈 500, 50글자씩 겹치게\n",
    "- 양자화 config: SQ(Scalar Quantization)\n",
    "- Query 엔진 연결시켜서 Q&A 사이클 완성시키기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 키 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 원천 데이터 -> LlamaIndex Document Object까지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document, VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "import nest_asyncio\n",
    "from llama_index.core.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "import qdrant_client\n",
    "from qdrant_client import models\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 로드\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 확인\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame 오브젝트로 변환\n",
    "data =\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document 오브젝트로 변환\n",
    "docs = []\n",
    "\n",
    "#Iterative하게 Document 만들기\n",
    "for i, row in data.iterrows():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document 오브젝트 Transformation을 위한 파이프라인 오브젝트 생성 - 요건: 청크사이즈 500, 오버랩 50\n",
    "pipeline = IngestionPipeline(\n",
    ")\n",
    "\n",
    "# 판다스 DataFrame -> 라마인덱스 다큐먼트 오브젝트로 변환\n",
    "nodes = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Qdrant 벡터스토어 셋업 및 데이터 인덱싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 LLM 설정 - Generation 모델: gpt-4o-mini, 임베딩 모델: text-embedding-3-small \n",
    "Settings.llm = \n",
    "Settings.embed_model =\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qdrant 클라우드 DB 연결\n",
    "client = qdrant_client.QdrantClient(\n",
    "    url=, \n",
    "    api_key=,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 내 실습용 콜렉션 생성 및 양자화 config 설정 - 요건: Scalar Quantization, 99퍼센타일\n",
    "client.recreate_collection(\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorstoreIndex의 Backend로써 storage_context 부여 및 인덱싱\n",
    "vector_store = QdrantVectorStore()\n",
    "storage_context = \n",
    "index = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.쿼리 엔진으로 인덱스 연결 및 샘플 쿼리 몇개 날려보는 것으로 Naive-RAG 마무리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 쿼리엔진에 연결\n",
    "query_engine = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#쿼리 날려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#쿼리 날려보기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
