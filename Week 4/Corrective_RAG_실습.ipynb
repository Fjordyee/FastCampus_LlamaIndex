{"cells":[{"cell_type":"code","source":["!pip install llama_index openai llama-index-tools-tavily-research"],"metadata":{"id":"pEtnBjGDv18c"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yMcDT8VmvyHf"},"outputs":[],"source":["import os\n","\n","os.environ[\"OPENAI_API_KEY\"] = \"\"\n","\n","tavily_ai_api_key = \"\"\n","from llama_index.llms.openai import OpenAI\n","from llama_index.embeddings.openai import OpenAIEmbedding\n","from llama_index.core import Settings\n","from pprint import pprint\n","# 사용 LLM 설정\n","Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n","Settings.embed_model = OpenAIEmbedding(\n","    model=\"text-embedding-3-small\"\n",")\n","import nest_asyncio\n","\n","nest_asyncio.apply()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KdqvQj_IvyHi"},"outputs":[],"source":["import pandas as pd\n","#korean_webtext.csv 불러오기\n","data = pd.read_csv().iloc[:,1:]\n","\n","# Document 오브젝트로 변환\n","from llama_index.core import Document, VectorStoreIndex\n","documents = []\n","\n","#Iterative하게 Document 만들기\n","for i, row in data.iterrows():\n","    documents.append(Document(\n","        text=row['text'],\n","        # extra_info={'title': row['title']}\n","    ))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hxFbuHs9vyHj"},"outputs":[],"source":["documents"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yF3kWK6UvyHk"},"outputs":[],"source":["\"\"\"Corrective RAG LlamaPack class.\"\"\"\n","\n","from typing import Any, Dict, List\n","\n","from llama_index.core import VectorStoreIndex, SummaryIndex\n","from llama_index.core.llama_pack.base import BaseLlamaPack\n","from llama_index.llms.openai import OpenAI\n","from llama_index.core.schema import Document, NodeWithScore\n","from llama_index.core.query_pipeline.query import QueryPipeline\n","from llama_index.tools.tavily_research.base import TavilyToolSpec\n","from llama_index.core.prompts import PromptTemplate\n","\n","DEFAULT_RELEVANCY_PROMPT_TEMPLATE = PromptTemplate(\n","    template=\"\"\"As a grader, your task is to evaluate the relevance of a document retrieved in response to a user's question.\n","\n","    Retrieved Document:\n","    -------------------\n","    {context_str}\n","\n","    User Question:\n","    --------------\n","    {query_str}\n","\n","    Evaluation Criteria:\n","    - Consider whether the document contains keywords or topics related to the user's question.\n","    - The evaluation should not be overly stringent; the primary objective is to identify and filter out clearly irrelevant retrievals.\n","\n","    Decision:\n","    - Assign a binary score to indicate the document's relevance.\n","    - Use 'yes' if the document is relevant to the question, or 'no' if it is not.\n","\n","    Please provide your binary score ('yes' or 'no') below to indicate the document's relevance to the user question.\"\"\"\n",")\n","\n","DEFAULT_TRANSFORM_QUERY_TEMPLATE = PromptTemplate(\n","    template=\"\"\"Your task is to refine a query to ensure it is highly effective for retrieving relevant search results. \\n\n","    Analyze the given input to grasp the core semantic intent or meaning. \\n\n","    Original Query:\n","    \\n ------- \\n\n","    {query_str}\n","    \\n ------- \\n\n","    Your goal is to rephrase or enhance this query to improve its search performance. Ensure the revised query is concise and directly aligned with the intended search objective. \\n\n","    Respond with the optimized query only:\"\"\"\n",")\n","\n","\n","class CorrectiveRAGPack(BaseLlamaPack):\n","    def __init__(self, documents: List[Document], tavily_ai_apikey: str) -> None:\n","        \"\"\"Init params.\"\"\"\n","        llm = OpenAI(model=\"gpt-4\") #GPT4?\n","        self.relevancy_pipeline = QueryPipeline(\n","            chain=[DEFAULT_RELEVANCY_PROMPT_TEMPLATE, llm]\n","        )\n","        self.transform_query_pipeline = QueryPipeline(\n","            chain=[DEFAULT_TRANSFORM_QUERY_TEMPLATE, llm]\n","        )\n","\n","        self.llm = llm\n","        self.index = VectorStoreIndex.from_documents(documents)\n","        self.tavily_tool = TavilyToolSpec(api_key=tavily_ai_apikey)\n","\n","    def get_modules(self) -> Dict[str, Any]:\n","        \"\"\"Get modules.\"\"\"\n","        return {\"llm\": self.llm, \"index\": self.index}\n","\n","    def retrieve_nodes(self, query_str: str, **kwargs: Any) -> List[NodeWithScore]:\n","        \"\"\"Retrieve the relevant nodes for the query.\"\"\"\n","        retriever = self.index.as_retriever(**kwargs)\n","        return retriever.retrieve(query_str)\n","\n","    def evaluate_relevancy(\n","        self, retrieved_nodes: List[Document], query_str: str\n","    ) -> List[str]:\n","        \"\"\"Evaluate relevancy of retrieved documents with the query.\"\"\"\n","        relevancy_results = []\n","        for node in retrieved_nodes:\n","            relevancy = self.relevancy_pipeline.run(\n","                context_str=node.text, query_str=query_str\n","            )\n","            relevancy_results.append(relevancy.message.content.lower().strip())\n","            print(f'Relevancy Result: {relevancy.message.content.lower().strip()}')\n","        return relevancy_results\n","\n","    def extract_relevant_texts(\n","        self, retrieved_nodes: List[NodeWithScore], relevancy_results: List[str]\n","    ) -> str:\n","        \"\"\"Extract relevant texts from retrieved documents.\"\"\"\n","        relevant_texts = [\n","            retrieved_nodes[i].text\n","            for i, result in enumerate(relevancy_results)\n","            if result == \"yes\"\n","        ]\n","        return \"\\n\".join(relevant_texts)\n","\n","    def search_with_transformed_query(self, query_str: str) -> str: #인터넷에서 찾은 결과인지 retrieved context인지 확인 필요\n","        \"\"\"Search the transformed query with Tavily API.\"\"\"\n","        search_results = self.tavily_tool.search(query_str, max_results=5)\n","        return \"\\n\".join([result.text for result in search_results])\n","\n","    def get_result(self, relevant_text: str, search_text: str, query_str: str) -> Any:\n","        \"\"\"Get result with relevant text.\"\"\"\n","        documents = [Document(text=relevant_text + \"\\n\" + search_text)]\n","        index = SummaryIndex.from_documents(documents)\n","        query_engine = index.as_query_engine()\n","        return query_engine.query(query_str)\n","\n","    def run(self, query_str: str, **kwargs: Any) -> Any:\n","        \"\"\"Run the pipeline.\"\"\"\n","        # Retrieve nodes based on the input query string.\n","        retrieved_nodes = self.retrieve_nodes(query_str, **kwargs)\n","        # 실행 시 retreive context 같이 띄워서 가독성 높이기\n","\n","\n","        # Evaluate the relevancy of each retrieved document in relation to the query string.\n","        relevancy_results = self.evaluate_relevancy(retrieved_nodes, query_str)\n","        # Extract texts from documents that are deemed relevant based on the evaluation.\n","        relevant_text = self.extract_relevant_texts(retrieved_nodes, relevancy_results)\n","\n","        # Initialize search_text variable to handle cases where it might not get defined.\n","        search_text = \"\"\n","\n","        # If any document is found irrelevant, transform the query string for better search results.\n","        if \"no\" in relevancy_results:\n","            transformed_query_str = self.transform_query_pipeline.run(\n","                query_str=query_str\n","            ).message.content\n","            # Conduct a search with the transformed query string and collect the results.\n","            search_text = self.search_with_transformed_query(transformed_query_str)\n","\n","        # Compile the final result. If there's additional search text from the transformed query,\n","        # it's included; otherwise, only the relevant text from the initial retrieval is returned.\n","        if search_text:\n","            return self.get_result(relevant_text, search_text, query_str)\n","        else:\n","            return self.get_result(relevant_text, \"\", query_str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8rqPw5mfvyHl"},"outputs":[],"source":["#corrective_rag 생성\n","corrective_rag_pack ="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k7jzBWkFvyHm"},"outputs":[],"source":["from IPython.display import Markdown, display\n","response = corrective_rag_pack.run()\n","display(Markdown(str(response)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4__G-4qhvyHn"},"outputs":[],"source":["#소스노드 확인\n","pprint()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"11dWgvlTvyHo"},"outputs":[],"source":["#소스노드 확인\n","pprint()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkNKLELivyHo"},"outputs":[],"source":["\n","response = corrective_rag_pack.run()\n","display(Markdown(str(response)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BNBfJ2XFvyHo"},"outputs":[],"source":["pprint(response.source_nodes[0].text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBSKPygwvyHp"},"outputs":[],"source":["pprint(response.source_nodes[1].text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qgz9RaOzvyHp"},"outputs":[],"source":["response = corrective_rag_pack.run()\n","display(Markdown(str(response)))"]},{"cell_type":"markdown","metadata":{"id":"HO_EZ35ovyHq"},"source":["- 기본 Retrieval 성능 개선이 필요하다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3x03WmxvyHr"},"outputs":[],"source":["from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n","from llama_index.core.query_engine import TransformQueryEngine"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"svJLZVxKvyHr"},"outputs":[],"source":["\"\"\"Corrective RAG LlamaPack class.\"\"\"\n","\n","from typing import Any, Dict, List\n","\n","from llama_index.core import VectorStoreIndex, SummaryIndex\n","from llama_index.core.llama_pack.base import BaseLlamaPack\n","from llama_index.llms.openai import OpenAI\n","from llama_index.core.schema import Document, NodeWithScore\n","from llama_index.core.query_pipeline.query import QueryPipeline\n","from llama_index.tools.tavily_research.base import TavilyToolSpec\n","from llama_index.core.prompts import PromptTemplate\n","\n","DEFAULT_RELEVANCY_PROMPT_TEMPLATE = PromptTemplate(\n","    template=\"\"\"As a grader, your task is to evaluate the relevance of a document retrieved in response to a user's question.\n","\n","    Retrieved Document:\n","    -------------------\n","    {context_str}\n","\n","    User Question:\n","    --------------\n","    {query_str}\n","\n","    Evaluation Criteria:\n","    - Consider whether the document contains keywords or topics related to the user's question.\n","    - The evaluation should not be overly stringent; the primary objective is to identify and filter out clearly irrelevant retrievals.\n","\n","    Decision:\n","    - Assign a binary score to indicate the document's relevance.\n","    - Use 'yes' if the document is relevant to the question, or 'no' if it is not.\n","\n","    Please provide your binary score ('yes' or 'no') below to indicate the document's relevance to the user question.\"\"\"\n",")\n","\n","DEFAULT_TRANSFORM_QUERY_TEMPLATE = PromptTemplate(\n","    template=\"\"\"Your task is to refine a query to ensure it is highly effective for retrieving relevant search results. \\n\n","    Analyze the given input to grasp the core semantic intent or meaning. \\n\n","    Original Query:\n","    \\n ------- \\n\n","    {query_str}\n","    \\n ------- \\n\n","    Your goal is to rephrase or enhance this query to improve its search performance. Ensure the revised query is concise and directly aligned with the intended search objective. \\n\n","    Respond with the optimized query only:\"\"\"\n",")\n","\n","\n","class CorrectiveRAGPack(BaseLlamaPack):\n","    def __init__(self, documents: List[Document], tavily_ai_apikey: str) -> None:\n","        \"\"\"Init params.\"\"\"\n","        llm = OpenAI(model=\"gpt-4o-mini\")\n","        self.relevancy_pipeline = QueryPipeline(\n","            chain=[DEFAULT_RELEVANCY_PROMPT_TEMPLATE, llm]\n","        )\n","        self.transform_query_pipeline = QueryPipeline(\n","            chain=[DEFAULT_TRANSFORM_QUERY_TEMPLATE, llm]\n","        )\n","\n","        self.llm = llm\n","        self.index = VectorStoreIndex.from_documents(documents)\n","        self.tavily_tool = TavilyToolSpec(api_key=tavily_ai_apikey)\n","        #hyde 생성\n","    def get_modules(self) -> Dict[str, Any]:\n","        \"\"\"Get modules.\"\"\"\n","        return {\"llm\": self.llm, \"index\": self.index}\n","\n","    def retrieve_nodes(self, query_str: str, **kwargs: Any) -> List[NodeWithScore]:\n","        \"\"\"Retrieve the relevant nodes for the query.\"\"\"\n","        retriever = self.index.as_retriever(**kwargs)\n","        # hyde 생성 가상 문서를 기준 임베딩으로 retrieve하는 구조로 변경\n","        return retriever.retrieve(query_str) #retrieve 수정\n","\n","\n","    def evaluate_relevancy(\n","        self, retrieved_nodes: List[Document], query_str: str\n","    ) -> List[str]:\n","        \"\"\"Evaluate relevancy of retrieved documents with the query.\"\"\"\n","        relevancy_results = []\n","        for node in retrieved_nodes:\n","            relevancy = self.relevancy_pipeline.run(\n","                context_str=node.text, query_str=query_str\n","            )\n","            relevancy_results.append(relevancy.message.content.lower().strip())\n","            print(f'Relevancy Result: {relevancy.message.content.lower().strip()}')\n","        return relevancy_results\n","\n","    def extract_relevant_texts(\n","        self, retrieved_nodes: List[NodeWithScore], relevancy_results: List[str]\n","    ) -> str:\n","        \"\"\"Extract relevant texts from retrieved documents.\"\"\"\n","        relevant_texts = [\n","            retrieved_nodes[i].text\n","            for i, result in enumerate(relevancy_results)\n","            if result == \"yes\"\n","        ]\n","        return \"\\n\".join(relevant_texts)\n","\n","    def search_with_transformed_query(self, query_str: str) -> str:\n","        \"\"\"Search the transformed query with Tavily API.\"\"\"\n","        print(f'Internet Search needed with query: {query_str}')\n","        search_results = self.tavily_tool.search(query_str, max_results=5)\n","        printing_result = \"\\n\".join([result.text for result in search_results])\n","        print(f'인터넷에서 찾은 검색결과: {printing_result}')\n","        return \"\\n\".join([result.text for result in search_results])\n","\n","    def get_result(self, relevant_text: str, search_text: str, query_str: str) -> Any:\n","        \"\"\"Get result with relevant text.\"\"\"\n","        documents = [Document(text=relevant_text + \"\\n\" + search_text)]\n","        index = SummaryIndex.from_documents(documents)\n","        query_engine = index.as_query_engine()\n","        return query_engine.query(query_str)\n","\n","    def run(self, query_str: str, **kwargs: Any) -> Any:\n","        \"\"\"Run the pipeline.\"\"\"\n","        # Retrieve nodes based on the input query string.\n","        retrieved_nodes = self.retrieve_nodes(query_str, **kwargs)\n","        pprint(f\"Retrieved Node 1: {retrieved_nodes[0].text}\")\n","        pprint(f\"Retrieved Node 2: {retrieved_nodes[1].text}\")\n","        # Evaluate the relevancy of each retrieved document in relation to the query string.\n","        relevancy_results = self.evaluate_relevancy(retrieved_nodes, query_str)\n","        # Extract texts from documents that are deemed relevant based on the evaluation.\n","        relevant_text = self.extract_relevant_texts(retrieved_nodes, relevancy_results)\n","\n","        # Initialize search_text variable to handle cases where it might not get defined.\n","        search_text = \"\"\n","\n","        # If any document is found irrelevant, transform the query string for better search results.\n","        if \"no\" in relevancy_results:\n","            transformed_query_str = self.transform_query_pipeline.run(\n","                query_str=query_str\n","            ).message.content\n","            # Conduct a search with the transformed query string and collect the results.\n","            search_text = self.search_with_transformed_query(transformed_query_str)\n","\n","        # Compile the final result. If there's additional search text from the transformed query,\n","        # it's included; otherwise, only the relevant text from the initial retrieval is returned.\n","        if search_text:\n","            return self.get_result(relevant_text, search_text, query_str)\n","        else:\n","            return self.get_result(relevant_text, \"\", query_str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0WspsKHOvyHs"},"outputs":[],"source":["corrective_rag_pack = CorrectiveRAGPack(documents, tavily_ai_apikey=tavily_ai_api_key)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OquR7D9vvyHs"},"outputs":[],"source":["#질문: \"캐나다가 주목받는 국가인 이유가 뭘까?\"\n","response = corrective_rag_pack.run()\n","display(Markdown(str(response)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tnZoxXXdvyHt"},"outputs":[],"source":["#질문: \"분당과 같은 도시가 외국에서도 통하려면 어떻게해야되?\"\n","response = corrective_rag_pack.run()\n","display(Markdown(str(response)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xX94ZSBAvyHt"},"outputs":[],"source":["#질문: \"일본과 러시아 전쟁 중 유명한게 뭐가 있지?\"\n","response = corrective_rag_pack.run()\n","display(Markdown(str(response)))"]},{"cell_type":"markdown","source":["- HyDE보다 retrieval 성능 개선해보자\n","- BM25+Dense Hybrid Search(RRF) + query decomposition"],"metadata":{"id":"D177oLG0y22A"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tGL9mQ6lvyHu"},"outputs":[],"source":["from typing import List\n","import asyncio\n","from llama_index.core import QueryBundle\n","from llama_index.core.retrievers import BaseRetriever\n","from llama_index.core.schema import NodeWithScore\n","from tqdm.asyncio import tqdm\n","\n","query_gen_str = \"\"\"\n","너는 사용자가 대충 쓴 질문에 대해서, 최대한 답변하기 위한 근거를 찾기 위한 다수의 서치 쿼리를 생성해 내야해.\n","생성하는 쿼리 중에 딱 하나는 역으로 된 질문으로 추가해서, 상대적 근거로 활용될 수 있도록 해야해.\n","{num_queries}개의 서치 쿼리를 만들어 내고, 하나당 한줄씩 사용해.\n","Query: {query}\n","Queries:\n","\"\"\"\n","query_gen_prompt = PromptTemplate(query_gen_str)\n","\n","llm = OpenAI(model=\"gpt-4o-mini\")\n","\n","def generate_queries(llm, query: str, num_queries: int = 4):\n","    response = llm.predict(\n","        query_gen_prompt, num_queries=num_queries, query=query\n","    )\n","    # assume LLM proper put each query on a newline\n","    queries = response.split(\"\\n\")\n","    queries_str = \"\\n\".join(queries)\n","    print(f\"Generated queries:\\n{queries_str}\")\n","    return queries\n","\n","async def run_queries(queries, retrievers):\n","    \"\"\"Run queries against retrievers.\"\"\"\n","    tasks = []\n","    for query in queries:\n","        for i, retriever in enumerate(retrievers):\n","            tasks.append(retriever.aretrieve(query))\n","\n","    task_results = await tqdm.gather(*tasks)\n","\n","    results_dict = {}\n","    for i, (query, query_result) in enumerate(zip(queries, task_results)):\n","        results_dict[(query, i)] = query_result\n","\n","    return results_dict\n","\n","def fuse_results(results_dict, similarity_top_k: int = 2):\n","    \"\"\"Fuse results.\"\"\"\n","    k = 60.0  # `k` is a parameter used to control the impact of outlier rankings.\n","    fused_scores = {}\n","    text_to_node = {}\n","\n","    # compute reciprocal rank scores\n","    for nodes_with_scores in results_dict.values():\n","        for rank, node_with_score in enumerate(\n","            sorted(\n","                nodes_with_scores, key=lambda x: x.score or 0.0, reverse=True\n","            )\n","        ):\n","            text = node_with_score.node.get_content()\n","            text_to_node[text] = node_with_score\n","            if text not in fused_scores:\n","                fused_scores[text] = 0.0\n","            fused_scores[text] += 1.0 / (rank + k)\n","\n","    # sort results\n","    reranked_results = dict(\n","        sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n","    )\n","\n","    # adjust node scores\n","    reranked_nodes: List[NodeWithScore] = []\n","    for text, score in reranked_results.items():\n","        reranked_nodes.append(text_to_node[text])\n","        reranked_nodes[-1].score = score\n","\n","    return reranked_nodes[:similarity_top_k]\n","\n","class FusionRetriever(BaseRetriever):\n","    \"\"\"Ensemble retriever with fusion.\"\"\"\n","\n","    def __init__(\n","        self,\n","        llm,\n","        retrievers: List[BaseRetriever],\n","        similarity_top_k: int = 2,\n","    ) -> None:\n","        \"\"\"Init params.\"\"\"\n","        self._retrievers = retrievers\n","        self._similarity_top_k = similarity_top_k\n","        self._llm = llm\n","        super().__init__()\n","\n","    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n","        \"\"\"Retrieve.\"\"\"\n","        queries = generate_queries(\n","            self._llm, query_bundle.query_str, num_queries=4\n","        )\n","        results = asyncio.run(run_queries(queries, self._retrievers))\n","        final_results = fuse_results(\n","            results, similarity_top_k=self._similarity_top_k\n","        )\n","\n","        return final_results"]},{"cell_type":"code","source":["!pip install llama-index-retrievers-bm25"],"metadata":{"id":"SsjzgBRtzC8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ed1_TRynvyHu"},"outputs":[],"source":["\"\"\"Corrective RAG LlamaPack class.\"\"\"\n","\n","from typing import Any, Dict, List\n","\n","from llama_index.core import VectorStoreIndex, SummaryIndex\n","from llama_index.core.llama_pack.base import BaseLlamaPack\n","from llama_index.llms.openai import OpenAI\n","from llama_index.core.schema import Document, NodeWithScore\n","from llama_index.core.query_pipeline.query import QueryPipeline\n","from llama_index.tools.tavily_research.base import TavilyToolSpec\n","from llama_index.core.prompts import PromptTemplate\n","from llama_index.retrievers.bm25 import BM25Retriever\n","DEFAULT_RELEVANCY_PROMPT_TEMPLATE = PromptTemplate(\n","    template=\"\"\"As a grader, your task is to evaluate the relevance of a document retrieved in response to a user's question.\n","\n","    Retrieved Document:\n","    -------------------\n","    {context_str}\n","\n","    User Question:\n","    --------------\n","    {query_str}\n","\n","    Evaluation Criteria:\n","    - Consider whether the document contains keywords or topics related to the user's question.\n","    - The evaluation should not be overly stringent; the primary objective is to identify and filter out clearly irrelevant retrievals.\n","\n","    Decision:\n","    - Assign a binary score to indicate the document's relevance.\n","    - Use 'yes' if the document is relevant to the question, or 'no' if it is not.\n","\n","    Please provide your binary score ('yes' or 'no') below to indicate the document's relevance to the user question.\"\"\"\n",")\n","\n","DEFAULT_TRANSFORM_QUERY_TEMPLATE = PromptTemplate(\n","    template=\"\"\"Your task is to refine a query to ensure it is highly effective for retrieving relevant search results. \\n\n","    Analyze the given input to grasp the core semantic intent or meaning. \\n\n","    Original Query:\n","    \\n ------- \\n\n","    {query_str}\n","    \\n ------- \\n\n","    Your goal is to rephrase or enhance this query to improve its search performance. Ensure the revised query is concise and directly aligned with the intended search objective. \\n\n","    Respond with the optimized query only:\"\"\"\n",")\n","\n","\n","class CorrectiveRAGPack(BaseLlamaPack):\n","    def __init__(self, documents: List[Document], tavily_ai_apikey: str) -> None:\n","        \"\"\"Init params.\"\"\"\n","        llm = OpenAI(model=\"gpt-4o-mini\")\n","        self.relevancy_pipeline = QueryPipeline(\n","            chain=[DEFAULT_RELEVANCY_PROMPT_TEMPLATE, llm]\n","        )\n","        self.transform_query_pipeline = QueryPipeline(\n","            chain=[DEFAULT_TRANSFORM_QUERY_TEMPLATE, llm]\n","        )\n","\n","        self.llm = llm\n","        self.index = VectorStoreIndex.from_documents(documents)\n","        self.tavily_tool = TavilyToolSpec(api_key=tavily_ai_apikey)\n","\n","    def get_modules(self) -> Dict[str, Any]:\n","        \"\"\"Get modules.\"\"\"\n","        return {\"llm\": self.llm, \"index\": self.index}\n","\n","    def retrieve_nodes(self, query_str: str, **kwargs: Any) -> List[NodeWithScore]:\n","        \"\"\"Retrieve the relevant nodes for the query.\"\"\"\n","        retriever = self.index.as_retriever(**kwargs)\n","        ## vector retriever 추가, 위에꺼 삭제\n","\n","\n","        ## bm25 retriever 추가\n","\n","        ## 결과 합치는 fusion retriever 추가\n","        return retriever.retrieve(query_str) #retriever 퓨전 리트리버로 교체\n","\n","\n","\n","    def evaluate_relevancy(\n","        self, retrieved_nodes: List[Document], query_str: str\n","    ) -> List[str]:\n","        \"\"\"Evaluate relevancy of retrieved documents with the query.\"\"\"\n","        relevancy_results = []\n","        for node in retrieved_nodes:\n","            relevancy = self.relevancy_pipeline.run(\n","                context_str=node.text, query_str=query_str\n","            )\n","            relevancy_results.append(relevancy.message.content.lower().strip())\n","            print(f'Relevancy Result: {relevancy.message.content.lower().strip()}')\n","        return relevancy_results\n","\n","    def extract_relevant_texts(\n","        self, retrieved_nodes: List[NodeWithScore], relevancy_results: List[str]\n","    ) -> str:\n","        \"\"\"Extract relevant texts from retrieved documents.\"\"\"\n","        relevant_texts = [\n","            retrieved_nodes[i].text\n","            for i, result in enumerate(relevancy_results)\n","            if result == \"yes\"\n","        ]\n","        return \"\\n\".join(relevant_texts)\n","\n","    def search_with_transformed_query(self, query_str: str) -> str:\n","        \"\"\"Search the transformed query with Tavily API.\"\"\"\n","        print(f'Internet Search needed with query: {query_str}')\n","        search_results = self.tavily_tool.search(query_str, max_results=5)\n","        printing_result = \"\\n\".join([result.text for result in search_results])\n","        print(f'인터넷에서 찾은 검색결과: {printing_result}')\n","        return \"\\n\".join([result.text for result in search_results])\n","\n","    def get_result(self, relevant_text: str, search_text: str, query_str: str) -> Any:\n","        \"\"\"Get result with relevant text.\"\"\"\n","        documents = [Document(text=relevant_text + \"\\n\" + search_text)]\n","        index = SummaryIndex.from_documents(documents)\n","        query_engine = index.as_query_engine()\n","        return query_engine.query(query_str)\n","\n","    def run(self, query_str: str, **kwargs: Any) -> Any:\n","        \"\"\"Run the pipeline.\"\"\"\n","        # Retrieve nodes based on the input query string.\n","        retrieved_nodes = self.retrieve_nodes(query_str, **kwargs)\n","        pprint(f\"Retrieved Node 1: {retrieved_nodes[0].text}\")\n","        pprint(f\"Retrieved Node 2: {retrieved_nodes[1].text}\")\n","        # Evaluate the relevancy of each retrieved document in relation to the query string.\n","        relevancy_results = self.evaluate_relevancy(retrieved_nodes, query_str)\n","        # Extract texts from documents that are deemed relevant based on the evaluation.\n","        relevant_text = self.extract_relevant_texts(retrieved_nodes, relevancy_results)\n","\n","        # Initialize search_text variable to handle cases where it might not get defined.\n","        search_text = \"\"\n","\n","        # If any document is found irrelevant, transform the query string for better search results.\n","        if \"no\" in relevancy_results:\n","            transformed_query_str = self.transform_query_pipeline.run(\n","                query_str=query_str\n","            ).message.content\n","            # Conduct a search with the transformed query string and collect the results.\n","            search_text = self.search_with_transformed_query(transformed_query_str)\n","\n","        # Compile the final result. If there's additional search text from the transformed query,\n","        # it's included; otherwise, only the relevant text from the initial retrieval is returned.\n","        if search_text:\n","            return self.get_result(relevant_text, search_text, query_str)\n","        else:\n","            return self.get_result(relevant_text, \"\", query_str)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"08qnOvJLvyHv"},"outputs":[],"source":["corrective_rag_pack = CorrectiveRAGPack(documents, tavily_ai_apikey=tavily_ai_api_key)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"guSER_jIvyHv"},"outputs":[],"source":["#질문:\n","response = corrective_rag_pack.run(\"캐나다가 주목받는 국가인 이유가 뭘까?\")\n","display(Markdown(str(response)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLbrJ2vkvyHw"},"outputs":[],"source":["response = corrective_rag_pack.run(\"분당과 같은 도시가 외국에서도 통하려면 어떻게해야되?\")\n","display(Markdown(str(response)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xxS_MI50vyHw"},"outputs":[],"source":["response = corrective_rag_pack.run(\"일본과 러시아 전쟁 중 유명한게 뭐가 있지?\")\n","display(Markdown(str(response)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oGInNI8VvyHw"},"outputs":[],"source":["#이제 Retrieval은 강화했는데 너무 기준이 빡세니까 관련성 크라이테리아를 좀 완화해보자\n","\"\"\"Corrective RAG LlamaPack class.\"\"\"\n","\n","from typing import Any, Dict, List\n","\n","from llama_index.core import VectorStoreIndex, SummaryIndex\n","from llama_index.core.llama_pack.base import BaseLlamaPack\n","from llama_index.llms.openai import OpenAI\n","from llama_index.core.schema import Document, NodeWithScore\n","from llama_index.core.query_pipeline.query import QueryPipeline\n","from llama_index.tools.tavily_research.base import TavilyToolSpec\n","from llama_index.core.prompts import PromptTemplate\n","from llama_index.retrievers.bm25 import BM25Retriever\n","DEFAULT_RELEVANCY_PROMPT_TEMPLATE = PromptTemplate(\n","    template=\"\"\"As a grader, your task is to evaluate the relevance of a document retrieved in response to a user's question.\n","\n","    Retrieved Document:\n","    -------------------\n","    {context_str}\n","\n","    User Question:\n","    --------------\n","    {query_str}\n","\n","    Evaluation Criteria: <- 덜빡세게 완화\n","    - Consider whether the document contains keywords or topics related to the user's question.\n","    - The evaluation should not be overly stringent; the primary objective is to identify and filter out clearly irrelevant retrievals.\n","\n","    Decision: <- 덜빡세게 완화\n","    - Assign a binary score to indicate the document's relevance.\n","    - Use 'yes' if the document is relevant to the question, or 'no' if it is not.\n","\n","    Please provide your binary score ('yes' or 'no') below to indicate the document's relevance to the user question.\"\"\"\n",")\n","\n","DEFAULT_TRANSFORM_QUERY_TEMPLATE = PromptTemplate(\n","    template=\"\"\"Your task is to refine a query to ensure it is highly effective for retrieving relevant search results. \\n\n","    Analyze the given input to grasp the core semantic intent or meaning. \\n\n","    Original Query:\n","    \\n ------- \\n\n","    {query_str}\n","    \\n ------- \\n\n","    Your goal is to rephrase or enhance this query to improve its search performance. Ensure the revised query is concise and directly aligned with the intended search objective. \\n\n","    Respond with the optimized query only:\"\"\"\n",")\n","\n","\n","class CorrectiveRAGPack(BaseLlamaPack):\n","    def __init__(self, documents: List[Document], tavily_ai_apikey: str) -> None:\n","        \"\"\"Init params.\"\"\"\n","        llm = OpenAI(model=\"gpt-4o-mini\")\n","        self.relevancy_pipeline = QueryPipeline(\n","            chain=[DEFAULT_RELEVANCY_PROMPT_TEMPLATE, llm]\n","        )\n","        self.transform_query_pipeline = QueryPipeline(\n","            chain=[DEFAULT_TRANSFORM_QUERY_TEMPLATE, llm]\n","        )\n","\n","        self.llm = llm\n","        self.index = VectorStoreIndex.from_documents(documents)\n","        self.tavily_tool = TavilyToolSpec(api_key=tavily_ai_apikey)\n","\n","    def get_modules(self) -> Dict[str, Any]:\n","        \"\"\"Get modules.\"\"\"\n","        return {\"llm\": self.llm, \"index\": self.index}\n","\n","    def retrieve_nodes(self, query_str: str, **kwargs: Any) -> List[NodeWithScore]:\n","        \"\"\"Retrieve the relevant nodes for the query.\"\"\"\n","        #retriever = self.index.as_retriever(**kwargs)\n","        ## vector retriever\n","        vector_retriever = self.index.as_retriever(similarity_top_k=2)\n","\n","        ## bm25 retriever\n","        bm25_retriever = BM25Retriever.from_defaults(\n","                        docstore=self.index.docstore, similarity_top_k=2\n","                        )\n","        fusion_retriever = FusionRetriever(\n","            self.llm, [vector_retriever, bm25_retriever], similarity_top_k=2\n","            )\n","        #return retriever.retrieve(query_str)\n","        return fusion_retriever.retrieve(query_str)\n","\n","\n","    def evaluate_relevancy(\n","        self, retrieved_nodes: List[Document], query_str: str\n","    ) -> List[str]:\n","        \"\"\"Evaluate relevancy of retrieved documents with the query.\"\"\"\n","        relevancy_results = []\n","        for node in retrieved_nodes:\n","            relevancy = self.relevancy_pipeline.run(\n","                context_str=node.text, query_str=query_str\n","            )\n","            relevancy_results.append(relevancy.message.content.lower().strip())\n","            print(f'Relevancy Result: {relevancy.message.content.lower().strip()}')\n","        return relevancy_results\n","\n","    def extract_relevant_texts(\n","        self, retrieved_nodes: List[NodeWithScore], relevancy_results: List[str]\n","    ) -> str:\n","        \"\"\"Extract relevant texts from retrieved documents.\"\"\"\n","        relevant_texts = [\n","            retrieved_nodes[i].text\n","            for i, result in enumerate(relevancy_results)\n","            if result == \"yes\"\n","        ]\n","        return \"\\n\".join(relevant_texts)\n","\n","    def search_with_transformed_query(self, query_str: str) -> str:\n","        \"\"\"Search the transformed query with Tavily API.\"\"\"\n","        print(f'Internet Search needed with query: {query_str}')\n","        search_results = self.tavily_tool.search(query_str, max_results=5)\n","        printing_result = \"\\n\".join([result.text for result in search_results])\n","        print(f'인터넷에서 찾은 검색결과: {printing_result}')\n","        return \"\\n\".join([result.text for result in search_results])\n","\n","    def get_result(self, relevant_text: str, search_text: str, query_str: str) -> Any:\n","        \"\"\"Get result with relevant text.\"\"\"\n","        documents = [Document(text=relevant_text + \"\\n\" + search_text)]\n","        index = SummaryIndex.from_documents(documents)\n","        query_engine = index.as_query_engine()\n","        return query_engine.query(query_str)\n","\n","    def run(self, query_str: str, **kwargs: Any) -> Any:\n","        \"\"\"Run the pipeline.\"\"\"\n","        # Retrieve nodes based on the input query string.\n","        retrieved_nodes = self.retrieve_nodes(query_str, **kwargs)\n","        pprint(f\"Retrieved Node 1: {retrieved_nodes[0].text}\")\n","        pprint(f\"Retrieved Node 2: {retrieved_nodes[1].text}\")\n","        # Evaluate the relevancy of each retrieved document in relation to the query string.\n","        relevancy_results = self.evaluate_relevancy(retrieved_nodes, query_str)\n","        # Extract texts from documents that are deemed relevant based on the evaluation.\n","        relevant_text = self.extract_relevant_texts(retrieved_nodes, relevancy_results)\n","\n","        # Initialize search_text variable to handle cases where it might not get defined.\n","        search_text = \"\"\n","\n","        # If any document is found irrelevant, transform the query string for better search results.\n","        if \"no\" in relevancy_results:\n","            transformed_query_str = self.transform_query_pipeline.run(\n","                query_str=query_str\n","            ).message.content\n","            # Conduct a search with the transformed query string and collect the results.\n","            search_text = self.search_with_transformed_query(transformed_query_str)\n","\n","        # Compile the final result. If there's additional search text from the transformed query,\n","        # it's included; otherwise, only the relevant text from the initial retrieval is returned.\n","        if search_text:\n","            return self.get_result(relevant_text, search_text, query_str)\n","        else:\n","            return self.get_result(relevant_text, \"\", query_str)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dAjzvdMCvyHx"},"outputs":[],"source":["corrective_rag_pack = CorrectiveRAGPack(documents, tavily_ai_apikey=tavily_ai_api_key)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H3c1RU9lvyHx"},"outputs":[],"source":["#질문: \"캐나다가 주목받는 국가인 이유가 뭘까?\"\n","response = corrective_rag_pack.run()\n","display(Markdown(str(response)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CJW629CEvyHx"},"outputs":[],"source":["#질문: \"분당과 같은 도시가 외국에서도 통하려면 어떻게해야되?\"\n","response = corrective_rag_pack.run()\n","display(Markdown(str(response)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aMFZVafgvyHy"},"outputs":[],"source":["pprint(response.source_nodes[0].text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cg8_fa3bvyHy"},"outputs":[],"source":["#질문: \"손흥민이 프리미어리그 득점왕때 몇골을 넣었지?\"\n","response = corrective_rag_pack.run()\n","display(Markdown(str(response)))"]},{"cell_type":"code","source":[],"metadata":{"id":"El_1KjLXzz5g"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"colab":{"provenance":[{"file_id":"1ATUisLdqzXTNR4cecGArpXFxyKCfGiTB","timestamp":1723184694706}]}},"nbformat":4,"nbformat_minor":0}