{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1exaR8Xk18cObyuHJXAPtAeqBS2PqIWUR","timestamp":1722584357740}],"gpuType":"T4","authorship_tag":"ABX9TyMgD9ljUIWGHgAXHbmzczbH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Bp9yXFRU9Wcz"},"outputs":[],"source":["!pip install llmlingua llama-index llama-index-postprocessor-longllmlingua"]},{"cell_type":"code","source":["# OpenAI 키 설정\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = ''\n","\n","from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n","from llama_index.core.response.pprint_utils import pprint_response\n","from llama_index.llms.openai import OpenAI\n","from llama_index.embeddings.openai import OpenAIEmbedding\n","from llama_index.core import Settings\n","\n","Settings.embed_model = OpenAIEmbedding(\n","    model=\"text-embedding-3-small\"\n",")\n","Settings.llm= OpenAI(model='gpt-4o-mini')"],"metadata":{"id":"lgCZ9w3e902b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 폴그라함 에쎼이 다큐먼트화\n","documents = SimpleDirectoryReader(\"/content/pg\").load_data()\n","\n","# 인덱스만들기\n","index = VectorStoreIndex.from_documents(documents=documents)\n","\n","# 시연 목적에 따라 long context retrieve 하고자 함\n","retriever = index.as_retriever()"],"metadata":{"id":"itFLAKYP-F2U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"Where did the author go for art school?\""],"metadata":{"id":"cfL_IoiR_Y52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["contexts ="],"metadata":{"id":"ZhDIjH0B_ptB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["context_list = [n.get_content() for n in contexts]"],"metadata":{"id":"Eoh720N5_sXq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["context_list"],"metadata":{"id":"Ikfour7G__ic"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#query_engine대신 vanilla하게 llm completion 호출\n","llm = OpenAI(model=\"gpt-4o-mini\")\n","prompt = \"\\n\\n\".join(context_list + [question])\n","\n","response = llm.complete(prompt)\n","print(str(response))"],"metadata":{"id":"vVqWYKq8_wzX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6RDJzl2u_wwq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.core.query_engine import RetrieverQueryEngine\n","from llama_index.core.response_synthesizers import CompactAndRefine\n","from llama_index.postprocessor.longllmlingua import LongLLMLinguaPostprocessor\n","\n","# Node Postprocessor : retrieve 이후 <-> generation 전. 즉, Augmentation 스테이지에서의 프로세서.\n","node_postprocessor = LongLLMLinguaPostprocessor(\n","    instruction_str=\"Given the context, please answer the final question\",\n","    target_token=300, # 목표로 하는 압축 토큰 수준\n","    rank_method=\"longllmlingua\",\n","    additional_compress_kwargs={\n","        \"condition_compare\": True, # Compress 작업 시 오리지널 쿼리를 고려할 것인지에 대한 세팅\n","        \"condition_in_question\": \"after\", # 고려 시 배치\n","        \"context_budget\": \"+100\", #default값 사용 추천\n","        \"reorder_context\": \"sort\",\n","        \"dynamic_context_compression_ratio\": 0.3, #default값 사용 추천\n","    },\n",")"],"metadata":{"id":"crMVuCvQ-b1J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compression 작업 위해 retrieved_nodes에 컨텍스트 청크 저장\n","retrieved_nodes = retriever.retrieve(question)\n","\n","# 추후 compressed context prompt 받을 시 response generation 방식 pre-define 해 놓은 것.\n","synthesizer = CompactAndRefine()"],"metadata":{"id":"zx-Vqrjx-k_G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.core.schema import QueryBundle\n","\n","# Compression 진행\n","new_retrieved_nodes = node_postprocessor.postprocess_nodes(\n","    retrieved_nodes, query_bundle=\n",")"],"metadata":{"id":"2NsEDhRQA2nV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compressed context 확인\n","new_retrieved_nodes"],"metadata":{"id":"afu0gpcuE6j4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["original_contexts = \"\\n\\n\".join([n.get_content() for n in retrieved_nodes])\n","compressed_contexts = \"\\n\\n\".join([n.get_content() for n in new_retrieved_nodes])\n","\n","# 기존의 토큰 수 카운트\n","original_tokens = node_postprocessor._llm_lingua.get_token_length(original_contexts)\n","# 컴프레스 완료된 토큰 수 카운트\n","compressed_tokens = node_postprocessor._llm_lingua.get_token_length(compressed_contexts)\n","\n","print(compressed_contexts)\n","print()\n","print(\"Original Tokens:\", original_tokens)\n","print(\"Compressed Tokens:\", compressed_tokens)\n","print(\"Compressed Ratio:\", f\"{original_tokens/(compressed_tokens + 1e-5):.2f}x\")"],"metadata":{"id":"InI1Un96A5oK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 최종적으로 답안 생성\n","response ="],"metadata":{"id":"cMAaYIVDBNCw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(str(response))"],"metadata":{"id":"-Cng0i7tBZhJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 한방에 하는법"],"metadata":{"id":"8K-iN2BeFPsW"}},{"cell_type":"code","source":["# 처음부터 QueryEngine으로 retriever 연결, 사전 정의한 노드 포스트프로세서 오브젝트만 참조\n","retriever_query_engine = RetrieverQueryEngine.from_args(\n","    retriever,\n",")"],"metadata":{"id":"6YudvMOCBbX1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response ="],"metadata":{"id":"jCG2NuipBin6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(str(response))"],"metadata":{"id":"PkVZvZvDBj3d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TXENK8E8BpyW"},"execution_count":null,"outputs":[]}]}